{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"DAC_approaching_probe_detection.ipynb","provenance":[],"collapsed_sections":[],"mount_file_id":"1Ugv-ePNMOMcGW3i9YD1mj3RZAB0OwJQ5","authorship_tag":"ABX9TyNGVY1R1xoM43CYHrpwzy5E"},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"74ZYHQ09wpho","executionInfo":{"status":"ok","timestamp":1604632132216,"user_tz":300,"elapsed":416,"user":{"displayName":"Archisman Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2bqPek-y6RYpqoQPDa5CAWcdutFVLCw5wHf8BtQ=s64","userId":"13495138657437974952"}},"outputId":"d013cccb-b3fc-463a-fead-1ace90ae9259","colab":{"base_uri":"https://localhost:8080/"}},"source":["a = model.predict(x_test)\n","np.argmax(a, axis=1)"],"execution_count":null,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([228, 244, 248, ...,  71, 248, 248])"]},"metadata":{"tags":[]},"execution_count":13}]},{"cell_type":"code","metadata":{"id":"KqQJOlcYCkeG","executionInfo":{"status":"error","timestamp":1604694578470,"user_tz":300,"elapsed":258,"user":{"displayName":"Archisman Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2bqPek-y6RYpqoQPDa5CAWcdutFVLCw5wHf8BtQ=s64","userId":"13495138657437974952"}},"outputId":"a8633098-1cfe-4654-9d4e-5e17a5910d7d","colab":{"base_uri":"https://localhost:8080/","height":165}},"source":["y_test.shape"],"execution_count":null,"outputs":[{"output_type":"error","ename":"NameError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-2-4f30429c224a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0my_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;31mNameError\u001b[0m: name 'y_test' is not defined"]}]},{"cell_type":"code","metadata":{"id":"SqpYosYAhNcn"},"source":[""],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"alkZbn5BhR5Z","executionInfo":{"status":"ok","timestamp":1605563377842,"user_tz":300,"elapsed":26388,"user":{"displayName":"Archisman Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2bqPek-y6RYpqoQPDa5CAWcdutFVLCw5wHf8BtQ=s64","userId":"13495138657437974952"}},"outputId":"3ca4156c-cb6b-4780-8b64-fbef1d8e951e","colab":{"base_uri":"https://localhost:8080/"}},"source":["import numpy as np\n","import tensorflow as tf\n","from tensorflow.keras.optimizers import Adam, Adadelta, RMSprop\n","from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\n","from tensorflow.keras.models import load_model\n","import gen_dataset\n","import matplotlib.pyplot as plt\n","import scipy.io as sio\n","\n","first = 1\n","accs = []\n","no_of_traces = []\n","keys_accuracy = []\n","\n","#param_range = np.linspace(12000, 46000, 10)\n","param_range = np.linspace(3500, 3500, 1)\n","for param in param_range:\n","    #opts = {\"Average\": {\"n_avg\": 1}, \"Resize\": {\"input_size\": 1250, \"num_traces\": int(param)}}\n","    opts = {\"Average\": {\"n_avg\": 1}}\n","        #\"PCA\":{\"k\":250}}\n","    #D = gen_dataset.gen_dataset([\"drive/My Drive/ML_unprotected_chip_AG\"], opts) #folder containing the trace file\n","    D = gen_dataset.gen_dataset([\"drive/My Drive/EM_PROBE_ATTACK_DETECTION_NPY\"], opts) #folder containing the trace file\n","    #D = gen_dataset.gen_dataset_new([\"drive/My Drive/MLSCA_TVTF_FINAL_SLIDE_NEW_DB\"], opts) #folder containing the trace file need to change gen_dataset_new fn \n","    #D = gen_dataset.gen_dataset([\"ML_ID_1Byte\"], opts)  # folder containing the trace file\n","    #D = gen_dataset.gen_dataset([\"MLSCA_DSAC_50K_Traces_2k_avg_with_a_wrong_key\"], opts)\n","    #D = gen_dataset.gen_dataset([\"MLSCA_DSAC_NPY\"], opts)\n","    x_train, y_train, x_val, y_val, x_test, y_test, input_size, output_size, model_choice = D\n","    #model_choice = 'cnn'\n","    model_dense = tf.keras.models.Sequential([\n","        tf.keras.layers.Reshape((input_size, ), input_shape=(input_size, )),\n","        tf.keras.layers.Dense(512, activation=tf.nn.relu,\n","                              kernel_regularizer=tf.keras.regularizers.l2(0.0)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(300, activation=tf.nn.relu,\n","                              kernel_regularizer=tf.keras.regularizers.l2(0.0)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(.2),\n","        tf.keras.layers.Dense(1500, activation=tf.nn.relu,\n","                              kernel_regularizer=tf.keras.regularizers.l2(0.0)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.01),\n","        tf.keras.layers.Dense(output_size, activation=tf.nn.softmax)\n","    ])\n","\n","    if model_choice == \"cnn\":\n","        model_cnn = tf.keras.models.Sequential([\n","            tf.keras.layers.Reshape((input_size, 1), input_shape=(input_size, )),\n","            tf.keras.layers.Conv1D(64, 5, activation=tf.nn.relu),\n","            tf.keras.layers.Conv1D(64, 5, activation=tf.nn.relu),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.MaxPool1D((3)),\n","            tf.keras.layers.Conv1D(128, 5, activation=tf.nn.relu),\n","            tf.keras.layers.Conv1D(128, 5, activation=tf.nn.relu),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.MaxPool1D((3)),\n","            tf.keras.layers.Conv1D(128, 5, activation=tf.nn.relu),\n","            tf.keras.layers.Conv1D(128, 5, activation=tf.nn.relu),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.MaxPool1D((3)),\n","            tf.keras.layers.Conv1D(128, 5, activation=tf.nn.relu),\n","            tf.keras.layers.Conv1D(128, 5, activation=tf.nn.relu),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.MaxPool1D((3)),\n","            tf.keras.layers.Flatten(),\n","            tf.keras.layers.Dropout(0.3),\n","            tf.keras.layers.Dense(1024, activation=tf.nn.relu,\n","                                  kernel_regularizer=tf.keras.regularizers.l2(0.0)),\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.Dense(256, activation=tf.nn.relu,\n","                                  kernel_regularizer=tf.keras.regularizers.l2(0.0)),\n","\n","            tf.keras.layers.BatchNormalization(),\n","            tf.keras.layers.Dropout(.4),\n","            tf.keras.layers.Dense(256, activation=tf.nn.softmax)\n","        ])\n","        model = model_cnn\n","\n","    if model_choice == \"spect_cnn\":\n","        spect_cnn = tf.keras.models.Sequential([\n","        tf.keras.layers.Reshape(x_train[0].shape + (1,), input_shape=x_train[0].shape),\n","        tf.keras.layers.Conv2D(250, 3, activation=tf.nn.relu),\n","        tf.keras.layers.Conv2D(250, 3, activation=tf.nn.relu),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.MaxPool2D((2, 2)),\n","        tf.keras.layers.Conv2D(150, 3, activation=tf.nn.relu),\n","        tf.keras.layers.Conv2D(150, 3, activation=tf.nn.relu),\n","    #    tf.keras.layers.MaxPool2D((2, 2)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Conv2D(50, 3, activation=tf.nn.relu),\n","        tf.keras.layers.Conv2D(50, 3, activation=tf.nn.relu),\n","        tf.keras.layers.MaxPool2D((2, 2)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Flatten(),\n","        tf.keras.layers.Dropout(0.3),\n","        tf.keras.layers.Dense(150, activation=tf.nn.relu,\n","                              kernel_regularizer=tf.keras.regularizers.l2(0.00)),\n","        tf.keras.layers.BatchNormalization(),\n","        tf.keras.layers.Dropout(0.2),\n","        tf.keras.layers.Dense(256, activation=tf.nn.softmax)\n","    ])\n","        model = spect_cnn\n","    else:\n","        model = model_dense\n","    adam = Adam(lr=0.00021)\n","    adadelta = Adadelta()\n","    rmsprop = RMSprop(lr=0.00001)\n","    chkpt = ModelCheckpoint('best_model.pkl', monitor='val_acc', save_best_only=True, mode='max', verbose=1)\n","    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, min_lr=0.0000001)\n","    model.compile(optimizer=adam,\n","                  loss='sparse_categorical_crossentropy',\n","                  metrics=['accuracy'])\n","    model.summary()\n","    #plt.plot(model.get_layer(\"dense\").get_weights()[0])\n","    #plt.show()\n","\n","    # if first == 1:\n","    #     print(\"saving Model\")\n","    #     model.save(\"tmp.h5\")\n","    #     first = 0\n","    # model = load_model(\"tmp.h5\")\n","    # print(\"loading model\")\n","    history = model.fit(x_train, y_train, validation_data=(x_val, y_val),\n","                       epochs=100, shuffle=True, batch_size=64, callbacks=[reduce_lr])\n","\n","    # model = tf.keras.models.load_model(\"dev2_only.h5\")\n","\n","    # TEST\n","    metrics = model.evaluate(x_test, y_test)\n","    print(metrics)\n","    accs.append(metrics[1]*100)\n","    no_of_traces.append(param*4)\n","    a = model.predict(x_test)\n","    b = np.argmax(a, axis=1)\n","    keys_accuracy.append(b)\n","    #model.save(\"devN1_4.h5\")\n","\n","    \"\"\"\n","    plt.plot(history.history['accuracy'], linewidth=2)\n","    plt.plot(history.history['val_accuracy'], linewidth=2)\n","    plt.title('Model Accuracy')\n","    plt.ylabel('Accuracy (%)', fontweight='bold')\n","    plt.xlabel('Epoch', fontweight='bold')\n","    plt.legend(['Train', 'Validation'], loc='lower right')\n","    plt.show()\n","\n","    plt.plot(model.get_layer(\"dense\").get_weights()[0])\n","    plt.show()\n","    \"\"\"\n","    # break\n","\n","#sio.savemat(\"test_accuracy_vs_traces_fpga.mat\", {\"test_accuracy\": accs, \"no_of_traces\": no_of_traces})\n","sio.savemat(\"test_accuracy_vs_traces_unprotected_test_part2.mat\", {\"test_accuracy2\": accs, \"no_of_traces2\": no_of_traces})\n","sio.savemat(\"test_accuracy_vs_traces_unprotected_cip_individual_prediction_test_part2.mat\", {\"keys_accuracy2\": keys_accuracy, \"no_of_traces2\": no_of_traces})\n","#sio.savemat(\"test_accuracy_vs_traces_DSAC_100M.mat\", {\"test_accuracy\": accs, \"no_of_traces\": no_of_traces})\n","#sio.savemat(\"test.mat\", {\"accuracy\": accs})\n","#plt.plot(param_range, accs)\n","#plt.show()"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Model: \"sequential_4\"\n","_________________________________________________________________\n","Layer (type)                 Output Shape              Param #   \n","=================================================================\n","reshape_4 (Reshape)          (None, 833)               0         \n","_________________________________________________________________\n","dense_16 (Dense)             (None, 512)               427008    \n","_________________________________________________________________\n","batch_normalization_12 (Batc (None, 512)               2048      \n","_________________________________________________________________\n","dropout_12 (Dropout)         (None, 512)               0         \n","_________________________________________________________________\n","dense_17 (Dense)             (None, 300)               153900    \n","_________________________________________________________________\n","batch_normalization_13 (Batc (None, 300)               1200      \n","_________________________________________________________________\n","dropout_13 (Dropout)         (None, 300)               0         \n","_________________________________________________________________\n","dense_18 (Dense)             (None, 1500)              451500    \n","_________________________________________________________________\n","batch_normalization_14 (Batc (None, 1500)              6000      \n","_________________________________________________________________\n","dropout_14 (Dropout)         (None, 1500)              0         \n","_________________________________________________________________\n","dense_19 (Dense)             (None, 256)               384256    \n","=================================================================\n","Total params: 1,425,912\n","Trainable params: 1,421,288\n","Non-trainable params: 4,624\n","_________________________________________________________________\n","Epoch 1/100\n","50/50 [==============================] - 0s 8ms/step - loss: 0.3635 - accuracy: 0.9475 - val_loss: 5.1145 - val_accuracy: 0.5253\n","Epoch 2/100\n","50/50 [==============================] - 0s 5ms/step - loss: 6.2358e-04 - accuracy: 1.0000 - val_loss: 4.7311 - val_accuracy: 0.5253\n","Epoch 3/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.2179e-04 - accuracy: 1.0000 - val_loss: 4.3494 - val_accuracy: 0.5253\n","Epoch 4/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.5213e-04 - accuracy: 1.0000 - val_loss: 3.9868 - val_accuracy: 0.5253\n","Epoch 5/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.2818e-04 - accuracy: 1.0000 - val_loss: 3.5930 - val_accuracy: 0.5253\n","Epoch 6/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.5597e-04 - accuracy: 1.0000 - val_loss: 3.1232 - val_accuracy: 0.9318\n","Epoch 7/100\n","50/50 [==============================] - 0s 6ms/step - loss: 1.8373e-04 - accuracy: 1.0000 - val_loss: 2.5568 - val_accuracy: 0.9899\n","Epoch 8/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.0921e-04 - accuracy: 1.0000 - val_loss: 1.8321 - val_accuracy: 0.9975\n","Epoch 9/100\n","50/50 [==============================] - 0s 4ms/step - loss: 1.5532e-04 - accuracy: 1.0000 - val_loss: 1.0291 - val_accuracy: 1.0000\n","Epoch 10/100\n","50/50 [==============================] - 0s 5ms/step - loss: 9.7332e-05 - accuracy: 1.0000 - val_loss: 0.3809 - val_accuracy: 1.0000\n","Epoch 11/100\n","50/50 [==============================] - 0s 6ms/step - loss: 7.7047e-05 - accuracy: 1.0000 - val_loss: 0.0863 - val_accuracy: 1.0000\n","Epoch 12/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.9044e-04 - accuracy: 1.0000 - val_loss: 0.0135 - val_accuracy: 1.0000\n","Epoch 13/100\n","50/50 [==============================] - 0s 5ms/step - loss: 8.2096e-05 - accuracy: 1.0000 - val_loss: 0.0022 - val_accuracy: 1.0000\n","Epoch 14/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.1440e-05 - accuracy: 1.0000 - val_loss: 4.0359e-04 - val_accuracy: 1.0000\n","Epoch 15/100\n","50/50 [==============================] - 0s 4ms/step - loss: 1.5200e-04 - accuracy: 1.0000 - val_loss: 9.7066e-05 - val_accuracy: 1.0000\n","Epoch 16/100\n","50/50 [==============================] - 0s 5ms/step - loss: 5.1624e-05 - accuracy: 1.0000 - val_loss: 3.2915e-05 - val_accuracy: 1.0000\n","Epoch 17/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.5437e-05 - accuracy: 1.0000 - val_loss: 1.4670e-05 - val_accuracy: 1.0000\n","Epoch 18/100\n","50/50 [==============================] - 0s 4ms/step - loss: 9.6279e-05 - accuracy: 1.0000 - val_loss: 8.5593e-06 - val_accuracy: 1.0000\n","Epoch 19/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.0106e-04 - accuracy: 1.0000 - val_loss: 5.5341e-06 - val_accuracy: 1.0000\n","Epoch 20/100\n","50/50 [==============================] - 0s 4ms/step - loss: 6.7268e-05 - accuracy: 1.0000 - val_loss: 4.4604e-06 - val_accuracy: 1.0000\n","Epoch 21/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.3171e-05 - accuracy: 1.0000 - val_loss: 3.8538e-06 - val_accuracy: 1.0000\n","Epoch 22/100\n","50/50 [==============================] - 0s 4ms/step - loss: 3.9432e-05 - accuracy: 1.0000 - val_loss: 3.4844e-06 - val_accuracy: 1.0000\n","Epoch 23/100\n","50/50 [==============================] - 0s 4ms/step - loss: 1.1755e-04 - accuracy: 1.0000 - val_loss: 3.3435e-06 - val_accuracy: 1.0000\n","Epoch 24/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.6251e-04 - accuracy: 1.0000 - val_loss: 3.0832e-06 - val_accuracy: 1.0000\n","Epoch 25/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.0274e-04 - accuracy: 1.0000 - val_loss: 2.9465e-06 - val_accuracy: 1.0000\n","Epoch 26/100\n","50/50 [==============================] - 0s 5ms/step - loss: 8.3103e-05 - accuracy: 1.0000 - val_loss: 2.8402e-06 - val_accuracy: 1.0000\n","Epoch 27/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.2730e-04 - accuracy: 1.0000 - val_loss: 2.7689e-06 - val_accuracy: 1.0000\n","Epoch 28/100\n","50/50 [==============================] - 0s 5ms/step - loss: 6.8219e-05 - accuracy: 1.0000 - val_loss: 2.6033e-06 - val_accuracy: 1.0000\n","Epoch 29/100\n","50/50 [==============================] - 0s 4ms/step - loss: 1.5222e-04 - accuracy: 1.0000 - val_loss: 2.5910e-06 - val_accuracy: 1.0000\n","Epoch 30/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.3247e-04 - accuracy: 1.0000 - val_loss: 2.5425e-06 - val_accuracy: 1.0000\n","Epoch 31/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.2976e-05 - accuracy: 1.0000 - val_loss: 2.4660e-06 - val_accuracy: 1.0000\n","Epoch 32/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.1307e-04 - accuracy: 1.0000 - val_loss: 2.5166e-06 - val_accuracy: 1.0000\n","Epoch 33/100\n","50/50 [==============================] - 0s 5ms/step - loss: 5.8337e-05 - accuracy: 1.0000 - val_loss: 2.4368e-06 - val_accuracy: 1.0000\n","Epoch 34/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.4562e-04 - accuracy: 1.0000 - val_loss: 2.3324e-06 - val_accuracy: 1.0000\n","Epoch 35/100\n","50/50 [==============================] - 0s 4ms/step - loss: 2.2188e-05 - accuracy: 1.0000 - val_loss: 2.3128e-06 - val_accuracy: 1.0000\n","Epoch 36/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.6998e-05 - accuracy: 1.0000 - val_loss: 2.2990e-06 - val_accuracy: 1.0000\n","Epoch 37/100\n","50/50 [==============================] - 0s 4ms/step - loss: 4.7721e-05 - accuracy: 1.0000 - val_loss: 2.2866e-06 - val_accuracy: 1.0000\n","Epoch 38/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.3935e-05 - accuracy: 1.0000 - val_loss: 2.2803e-06 - val_accuracy: 1.0000\n","Epoch 39/100\n","50/50 [==============================] - 0s 5ms/step - loss: 7.9063e-05 - accuracy: 1.0000 - val_loss: 2.2954e-06 - val_accuracy: 1.0000\n","Epoch 40/100\n","50/50 [==============================] - 0s 6ms/step - loss: 2.7815e-05 - accuracy: 1.0000 - val_loss: 2.2896e-06 - val_accuracy: 1.0000\n","Epoch 41/100\n","50/50 [==============================] - 0s 6ms/step - loss: 8.3865e-05 - accuracy: 1.0000 - val_loss: 2.2890e-06 - val_accuracy: 1.0000\n","Epoch 42/100\n","50/50 [==============================] - 0s 6ms/step - loss: 2.9175e-05 - accuracy: 1.0000 - val_loss: 2.2824e-06 - val_accuracy: 1.0000\n","Epoch 43/100\n","50/50 [==============================] - 0s 6ms/step - loss: 5.3780e-05 - accuracy: 1.0000 - val_loss: 2.2776e-06 - val_accuracy: 1.0000\n","Epoch 44/100\n","50/50 [==============================] - 0s 5ms/step - loss: 9.9418e-05 - accuracy: 1.0000 - val_loss: 2.2514e-06 - val_accuracy: 1.0000\n","Epoch 45/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.3860e-05 - accuracy: 1.0000 - val_loss: 2.2487e-06 - val_accuracy: 1.0000\n","Epoch 46/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.5923e-05 - accuracy: 1.0000 - val_loss: 2.2415e-06 - val_accuracy: 1.0000\n","Epoch 47/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.7488e-05 - accuracy: 1.0000 - val_loss: 2.2915e-06 - val_accuracy: 1.0000\n","Epoch 48/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.1524e-05 - accuracy: 1.0000 - val_loss: 2.2833e-06 - val_accuracy: 1.0000\n","Epoch 49/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.3850e-05 - accuracy: 1.0000 - val_loss: 2.2845e-06 - val_accuracy: 1.0000\n","Epoch 50/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.2051e-05 - accuracy: 1.0000 - val_loss: 2.2918e-06 - val_accuracy: 1.0000\n","Epoch 51/100\n","50/50 [==============================] - 0s 5ms/step - loss: 5.7251e-05 - accuracy: 1.0000 - val_loss: 2.2740e-06 - val_accuracy: 1.0000\n","Epoch 52/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.1187e-05 - accuracy: 1.0000 - val_loss: 2.2842e-06 - val_accuracy: 1.0000\n","Epoch 53/100\n","50/50 [==============================] - 0s 5ms/step - loss: 9.3159e-05 - accuracy: 1.0000 - val_loss: 2.2144e-06 - val_accuracy: 1.0000\n","Epoch 54/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.8540e-05 - accuracy: 1.0000 - val_loss: 2.2601e-06 - val_accuracy: 1.0000\n","Epoch 55/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.8514e-05 - accuracy: 1.0000 - val_loss: 2.2595e-06 - val_accuracy: 1.0000\n","Epoch 56/100\n","50/50 [==============================] - 0s 4ms/step - loss: 3.8204e-05 - accuracy: 1.0000 - val_loss: 2.2797e-06 - val_accuracy: 1.0000\n","Epoch 57/100\n","50/50 [==============================] - 0s 5ms/step - loss: 6.2940e-05 - accuracy: 1.0000 - val_loss: 2.2436e-06 - val_accuracy: 1.0000\n","Epoch 58/100\n","50/50 [==============================] - 0s 4ms/step - loss: 4.5656e-05 - accuracy: 1.0000 - val_loss: 2.2683e-06 - val_accuracy: 1.0000\n","Epoch 59/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.3084e-05 - accuracy: 1.0000 - val_loss: 2.2981e-06 - val_accuracy: 1.0000\n","Epoch 60/100\n","50/50 [==============================] - 0s 4ms/step - loss: 2.9310e-05 - accuracy: 1.0000 - val_loss: 2.2644e-06 - val_accuracy: 1.0000\n","Epoch 61/100\n","50/50 [==============================] - 0s 4ms/step - loss: 7.4859e-05 - accuracy: 1.0000 - val_loss: 2.2749e-06 - val_accuracy: 1.0000\n","Epoch 62/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.8451e-05 - accuracy: 1.0000 - val_loss: 2.2689e-06 - val_accuracy: 1.0000\n","Epoch 63/100\n","50/50 [==============================] - 0s 5ms/step - loss: 5.1107e-05 - accuracy: 1.0000 - val_loss: 2.2520e-06 - val_accuracy: 1.0000\n","Epoch 64/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.0228e-04 - accuracy: 1.0000 - val_loss: 2.2788e-06 - val_accuracy: 1.0000\n","Epoch 65/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.8342e-05 - accuracy: 1.0000 - val_loss: 2.2707e-06 - val_accuracy: 1.0000\n","Epoch 66/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.5449e-05 - accuracy: 1.0000 - val_loss: 2.2683e-06 - val_accuracy: 1.0000\n","Epoch 67/100\n","50/50 [==============================] - 0s 5ms/step - loss: 9.5557e-05 - accuracy: 1.0000 - val_loss: 2.2376e-06 - val_accuracy: 1.0000\n","Epoch 68/100\n","50/50 [==============================] - 0s 6ms/step - loss: 4.2974e-05 - accuracy: 1.0000 - val_loss: 2.2246e-06 - val_accuracy: 1.0000\n","Epoch 69/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.3929e-05 - accuracy: 1.0000 - val_loss: 2.2409e-06 - val_accuracy: 1.0000\n","Epoch 70/100\n","50/50 [==============================] - 0s 5ms/step - loss: 5.0575e-05 - accuracy: 1.0000 - val_loss: 2.2598e-06 - val_accuracy: 1.0000\n","Epoch 71/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.6843e-04 - accuracy: 1.0000 - val_loss: 2.3167e-06 - val_accuracy: 1.0000\n","Epoch 72/100\n","50/50 [==============================] - 0s 4ms/step - loss: 5.4251e-05 - accuracy: 1.0000 - val_loss: 2.2818e-06 - val_accuracy: 1.0000\n","Epoch 73/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.9189e-05 - accuracy: 1.0000 - val_loss: 2.2899e-06 - val_accuracy: 1.0000\n","Epoch 74/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.0834e-05 - accuracy: 1.0000 - val_loss: 2.2836e-06 - val_accuracy: 1.0000\n","Epoch 75/100\n","50/50 [==============================] - 0s 5ms/step - loss: 5.6434e-05 - accuracy: 1.0000 - val_loss: 2.2638e-06 - val_accuracy: 1.0000\n","Epoch 76/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.0073e-05 - accuracy: 1.0000 - val_loss: 2.2601e-06 - val_accuracy: 1.0000\n","Epoch 77/100\n","50/50 [==============================] - 0s 4ms/step - loss: 3.8327e-05 - accuracy: 1.0000 - val_loss: 2.2430e-06 - val_accuracy: 1.0000\n","Epoch 78/100\n","50/50 [==============================] - 0s 5ms/step - loss: 7.6754e-05 - accuracy: 1.0000 - val_loss: 2.2406e-06 - val_accuracy: 1.0000\n","Epoch 79/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.7841e-05 - accuracy: 1.0000 - val_loss: 2.2421e-06 - val_accuracy: 1.0000\n","Epoch 80/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.8251e-05 - accuracy: 1.0000 - val_loss: 2.2340e-06 - val_accuracy: 1.0000\n","Epoch 81/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.7467e-04 - accuracy: 1.0000 - val_loss: 2.2797e-06 - val_accuracy: 1.0000\n","Epoch 82/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.0089e-04 - accuracy: 1.0000 - val_loss: 2.2788e-06 - val_accuracy: 1.0000\n","Epoch 83/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.7847e-05 - accuracy: 1.0000 - val_loss: 2.2713e-06 - val_accuracy: 1.0000\n","Epoch 84/100\n","50/50 [==============================] - 0s 6ms/step - loss: 4.3361e-05 - accuracy: 1.0000 - val_loss: 2.2613e-06 - val_accuracy: 1.0000\n","Epoch 85/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.2440e-05 - accuracy: 1.0000 - val_loss: 2.2770e-06 - val_accuracy: 1.0000\n","Epoch 86/100\n","50/50 [==============================] - 0s 5ms/step - loss: 6.3587e-05 - accuracy: 1.0000 - val_loss: 2.2644e-06 - val_accuracy: 1.0000\n","Epoch 87/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.1836e-05 - accuracy: 1.0000 - val_loss: 2.2165e-06 - val_accuracy: 1.0000\n","Epoch 88/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.4915e-05 - accuracy: 1.0000 - val_loss: 2.2343e-06 - val_accuracy: 1.0000\n","Epoch 89/100\n","50/50 [==============================] - 0s 5ms/step - loss: 6.2604e-05 - accuracy: 1.0000 - val_loss: 2.2315e-06 - val_accuracy: 1.0000\n","Epoch 90/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.5643e-05 - accuracy: 1.0000 - val_loss: 2.2463e-06 - val_accuracy: 1.0000\n","Epoch 91/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.0115e-05 - accuracy: 1.0000 - val_loss: 2.2653e-06 - val_accuracy: 1.0000\n","Epoch 92/100\n","50/50 [==============================] - 0s 5ms/step - loss: 4.3384e-05 - accuracy: 1.0000 - val_loss: 2.2791e-06 - val_accuracy: 1.0000\n","Epoch 93/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.4136e-05 - accuracy: 1.0000 - val_loss: 2.2635e-06 - val_accuracy: 1.0000\n","Epoch 94/100\n","50/50 [==============================] - 0s 4ms/step - loss: 6.3380e-04 - accuracy: 1.0000 - val_loss: 2.2586e-06 - val_accuracy: 1.0000\n","Epoch 95/100\n","50/50 [==============================] - 0s 5ms/step - loss: 8.6677e-05 - accuracy: 1.0000 - val_loss: 2.2662e-06 - val_accuracy: 1.0000\n","Epoch 96/100\n","50/50 [==============================] - 0s 5ms/step - loss: 3.3728e-05 - accuracy: 1.0000 - val_loss: 2.2553e-06 - val_accuracy: 1.0000\n","Epoch 97/100\n","50/50 [==============================] - 0s 5ms/step - loss: 6.5266e-05 - accuracy: 1.0000 - val_loss: 2.2740e-06 - val_accuracy: 1.0000\n","Epoch 98/100\n","50/50 [==============================] - 0s 5ms/step - loss: 1.5388e-04 - accuracy: 1.0000 - val_loss: 2.2457e-06 - val_accuracy: 1.0000\n","Epoch 99/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.1220e-05 - accuracy: 1.0000 - val_loss: 2.2207e-06 - val_accuracy: 1.0000\n","Epoch 100/100\n","50/50 [==============================] - 0s 5ms/step - loss: 2.4341e-05 - accuracy: 1.0000 - val_loss: 2.2418e-06 - val_accuracy: 1.0000\n","13/13 [==============================] - 0s 2ms/step - loss: 3.0586e-05 - accuracy: 1.0000\n","[3.058617949136533e-05, 1.0]\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"8LrpW0aeQQ75","executionInfo":{"status":"ok","timestamp":1605563381597,"user_tz":300,"elapsed":160,"user":{"displayName":"Archisman Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2bqPek-y6RYpqoQPDa5CAWcdutFVLCw5wHf8BtQ=s64","userId":"13495138657437974952"}},"outputId":"bee86647-93aa-4d3e-af43-29d64cb69c6c","colab":{"base_uri":"https://localhost:8080/"}},"source":["y_test"],"execution_count":7,"outputs":[{"output_type":"execute_result","data":{"text/plain":["array([101., 101., 101., 103., 103., 103., 103., 101., 101., 101., 103.,\n","       101., 101., 101., 101., 103., 103., 103., 103., 103., 103., 103.,\n","       103., 103., 101., 101., 103., 101., 101., 102., 101., 103., 103.,\n","       103., 101., 103., 101., 103., 101., 103., 101., 101., 101., 101.,\n","       101., 103., 101., 101., 101., 101., 101., 103., 101., 101., 101.,\n","       101., 101., 101., 103., 101., 101., 101., 101., 103., 101., 101.,\n","       103., 103., 101., 101., 101., 101., 103., 103., 103., 103., 103.,\n","       103., 103., 101., 103., 103., 103., 103., 103., 103., 101., 101.,\n","       103., 101., 103., 103., 103., 101., 101., 101., 101., 101., 101.,\n","       101., 101., 101., 101., 101., 101., 101., 103., 101., 101., 101.,\n","       101., 101., 103., 103., 103., 103., 101., 101., 102., 103., 101.,\n","       101., 101., 103., 101., 103., 101., 103., 103., 101., 103., 101.,\n","       103., 101., 103., 101., 101., 101., 101., 103., 103., 103., 101.,\n","       103., 103., 101., 103., 103., 101., 101., 103., 101., 101., 101.,\n","       103., 101., 101., 101., 103., 101., 103., 103., 103., 103., 103.,\n","       103., 101., 103., 103., 101., 101., 103., 101., 101., 103., 103.,\n","       101., 103., 103., 103., 101., 103., 103., 103., 101., 101., 101.,\n","       103., 101., 101., 101., 101., 103., 103., 103., 103., 101., 101.,\n","       103., 101., 103., 103., 101., 103., 101., 103., 103., 103., 102.,\n","       103., 103., 101., 103., 101., 103., 101., 103., 103., 103., 101.,\n","       101., 103., 103., 101., 101., 101., 101., 103., 103., 103., 103.,\n","       103., 103., 103., 101., 101., 103., 101., 101., 101., 101., 103.,\n","       101., 103., 103., 101., 101., 103., 101., 103., 101., 101., 103.,\n","       103., 103., 103., 103., 103., 101., 101., 101., 101., 103., 102.,\n","       103., 101., 103., 101., 102., 103., 102., 101., 103., 103., 103.,\n","       103., 103., 101., 103., 101., 101., 101., 103., 103., 101., 101.,\n","       103., 103., 103., 101., 101., 101., 101., 103., 101., 103., 101.,\n","       101., 101., 103., 101., 103., 103., 103., 101., 101., 102., 101.,\n","       101., 103., 101., 103., 103., 101., 101., 103., 103., 101., 103.,\n","       103., 103., 101., 101., 102., 103., 101., 101., 103., 103., 101.,\n","       101., 101., 103., 101., 101., 101., 103., 103., 103., 103., 101.,\n","       101., 101., 103., 101., 103., 103., 103., 101., 102., 103., 103.,\n","       103., 101., 101., 102., 101., 103., 103., 101., 101., 101., 103.,\n","       101., 101., 102., 101., 103., 103., 103., 101., 103., 103., 101.,\n","       103., 101., 103., 101., 103., 103., 102., 103., 101., 103., 101.,\n","       103., 101., 101., 101., 103., 101., 103., 103., 101., 101., 103.])"]},"metadata":{"tags":[]},"execution_count":7}]},{"cell_type":"code","metadata":{"id":"5rwSsvQ0ta1F","executionInfo":{"status":"ok","timestamp":1605562306945,"user_tz":300,"elapsed":1961,"user":{"displayName":"Archisman Ghosh","photoUrl":"https://lh3.googleusercontent.com/a-/AOh14Gj2bqPek-y6RYpqoQPDa5CAWcdutFVLCw5wHf8BtQ=s64","userId":"13495138657437974952"}}},"source":["import sys\n","sys.path.insert(0, 'drive/My Drive/ML_unprotected_chip_AG')\n","import gen_dataset"],"execution_count":1,"outputs":[]}]}